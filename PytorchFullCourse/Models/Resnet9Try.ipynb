{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdb7facd-e46b-477e-a039-a9ef94836711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "356745a5-5cfb-4de5-a488-8cfde2775a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.TrivialAugmentWide(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "train_data = datasets.CIFAR10(root=\"../data\", download=False, train=True, transform=trans)\n",
    "test_data = datasets.CIFAR10(root=\"../data\", download=False, train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a88d663-66e2-4fda-a8b1-dc41ad03aee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "train_dataloader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1632846a-e544-4086-9213-b89c4a0e5fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "              nn.BatchNorm2d(out_channels),\n",
    "              nn.ReLU(inplace=True)\n",
    "             ]\n",
    "    if pool: layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9282a73a-d23d-4ca4-a38d-a12f66333ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet9(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = conv_block(in_channels, 64)\n",
    "        self.conv2 = conv_block(64, 128, pool=True)\n",
    "        self.resnet1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n",
    "\n",
    "        self.conv3 = conv_block(128, 256, pool=True)\n",
    "        self.conv4 = conv_block(256, 512, pool=True)\n",
    "        self.resnet2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n",
    "\n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n",
    "                                       nn.Flatten(),\n",
    "                                       nn.Linear(512, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.resnet1(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.resnet2(out) + out\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "        \n",
    "device = \"cuda\"\n",
    "model = Resnet9(3, 10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96e83f19-b668-4b6d-844a-60cb3a75bd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1876,  3.0599,  0.4671,  0.3286, -2.3667, -1.6634, -2.4628,  3.8249,\n",
       "          0.6262,  0.7074]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "test = torch.rand(1, 3, 32, 32).to(device)\n",
    "model(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a947e54e-c938-4aa7-b828-dc3cd55f2c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, weight_decay=0.0001)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.2)\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ad62b05-6a65-4d03-899b-703ec6168548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0, loss : 3.0364, loss_test : 1.8241, acc : 32.990, lr : 0.10000\n",
      "epoch : 1, loss : 1.5945, loss_test : 1.0614, acc : 61.600, lr : 0.10000\n",
      "epoch : 2, loss : 1.2576, loss_test : 0.8913, acc : 69.080, lr : 0.10000\n",
      "epoch : 3, loss : 1.0894, loss_test : 0.6882, acc : 75.960, lr : 0.10000\n",
      "epoch : 4, loss : 0.9746, loss_test : 0.6417, acc : 78.240, lr : 0.10000\n",
      "epoch : 5, loss : 0.8938, loss_test : 0.5539, acc : 80.720, lr : 0.10000\n",
      "epoch : 6, loss : 0.8437, loss_test : 0.5411, acc : 81.120, lr : 0.10000\n",
      "epoch : 7, loss : 0.7884, loss_test : 0.5015, acc : 82.570, lr : 0.10000\n",
      "epoch : 8, loss : 0.7622, loss_test : 0.5142, acc : 82.270, lr : 0.10000\n",
      "epoch : 9, loss : 0.7263, loss_test : 0.5411, acc : 81.960, lr : 0.02000\n",
      "epoch : 10, loss : 0.5714, loss_test : 0.3813, acc : 86.970, lr : 0.02000\n",
      "epoch : 11, loss : 0.5376, loss_test : 0.3658, acc : 87.900, lr : 0.02000\n",
      "epoch : 12, loss : 0.5163, loss_test : 0.3619, acc : 87.780, lr : 0.02000\n",
      "epoch : 13, loss : 0.5077, loss_test : 0.3559, acc : 88.030, lr : 0.02000\n",
      "epoch : 14, loss : 0.4920, loss_test : 0.3503, acc : 88.320, lr : 0.02000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(299, 'sec')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from timeit import default_timer as timer\n",
    "start = timer()\n",
    "for epoch in range(epochs):\n",
    "    loss_train = 0\n",
    "    for x, y in train_dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss_train += loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    loss_train /= len(train_dataloader)\n",
    "    loss_test, acc =  0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for x, y in test_dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss_test += criterion(y_pred, y)\n",
    "            acc += accuracy_score(torch.softmax(y_pred, dim=1).argmax(dim=1).cpu(), y.cpu())\n",
    "        loss_test /= len(test_dataloader)\n",
    "        acc /= len(test_dataloader)\n",
    "    print(f\"epoch : {epoch}, loss : {loss_train:.4f}, loss_test : {loss_test:.4f}, acc : {(acc*100):.3f}, lr : {optimizer.state_dict()['param_groups'][0]['lr']:.5f}\")\n",
    "end = timer()\n",
    "round(end-start), \"sec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac3b993-1175-4db3-88f4-8fecf59461c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e7cfd0-bd8a-4313-8f20-e73231763712",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
